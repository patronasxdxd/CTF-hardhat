{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlu0YtpEpVNLCEIbjFMKJL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patronasxdxd/CTF-hardhat/blob/master/deeplearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ezYwUnAgWdtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "def scrape_google_images(query):\n",
        "    url = f\"https://www.google.com/search?q={query}&tbm=isch&tbs=isz:l\"\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    images = []\n",
        "    for img in soup.find_all(\"img\"):\n",
        "        img_url = img.get(\"src\")\n",
        "        if img_url and img_url.startswith(\"http\"):\n",
        "            images.append(img_url)\n",
        "\n",
        "    return images\n",
        "\n",
        "\n",
        "# Example usage\n",
        "kanye_images = scrape_google_images(\"kanye west face front\")\n",
        "ariana_images = scrape_google_images(\"ariana grande Face front\")\n",
        "kanye_lookalike_images = scrape_google_images(\"micheal b jordan face front\")\n",
        "ariana_lookalike_images = scrape_google_images(\"bella hadid face front\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n2Col58MWe2c"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWiPkG0NWSPm",
        "outputId": "b4848b04-aea3-40e9-9a17-ce34dc9ef092"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Kanye West images\n",
            "\n",
            "Processing Ice Spice images\n",
            "\n",
            "Processing Ice Spice images\n",
            "\n",
            "Processing Ice Spice images\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import requests\n",
        "from tempfile import NamedTemporaryFile\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "\n",
        "def get_image_from_url(url):\n",
        "    response = requests.get(url)\n",
        "    image = Image.open(BytesIO(response.content))\n",
        "    image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
        "    return image\n",
        "\n",
        "def process_and_save_images(image_urls, dir_name, max_faces=10):\n",
        "    faces_found = 0\n",
        "    if not os.path.exists(dir_name):\n",
        "        os.makedirs(dir_name)\n",
        "\n",
        "    for url in image_urls:\n",
        "        if faces_found >= max_faces:\n",
        "            break\n",
        "        try:\n",
        "            img = get_image_from_url(url)\n",
        "            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            faces = faceCascade.detectMultiScale(img_gray, scaleFactor=1.2, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "            if len(faces) == 1:\n",
        "                x, y, w, h = faces[0]\n",
        "                cropped_face = img[y:y+h, x:x+w]  # Crop the face from the image\n",
        "                faces_found += 1\n",
        "                cv2.imwrite(os.path.join(dir_name, f'{faces_found}.jpg'), cropped_face)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image {url}: {e}\")\n",
        "\n",
        "# URL of the Haarcascade Frontal Face Classifier\n",
        "trained_haarcascade_url = \"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\"\n",
        "\n",
        "# Load Haarcascade Classifier into a temporary file\n",
        "response = requests.get(trained_haarcascade_url)\n",
        "with NamedTemporaryFile(delete=False, suffix='.xml') as temp_file:\n",
        "    temp_file.write(response.content)\n",
        "    temp_file_path = temp_file.name\n",
        "\n",
        "# Load the classifier from the temporary file\n",
        "faceCascade = cv2.CascadeClassifier(temp_file_path)\n",
        "\n",
        "# Process images for each celebrity\n",
        "print(\"Processing Kanye West images\")\n",
        "process_and_save_images(kanye_images, 'dataset/train/kanye')\n",
        "\n",
        "print(\"\\nProcessing Ice Spice images\")\n",
        "process_and_save_images(ariana_images,'dataset/train/ariana')\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nProcessing Ice Spice images\")\n",
        "process_and_save_images(kanye_lookalike_images, 'dataset/validation/kanyelookalike')\n",
        "\n",
        "\n",
        "print(\"\\nProcessing Ice Spice images\")\n",
        "process_and_save_images(ariana_lookalike_images, 'dataset/validation/arianalookalike')\n",
        "\n",
        "\n",
        "from PIL import Image, ImageEnhance, ImageFilter\n",
        "import random\n",
        "\n",
        "# adding blurs and brightness\n",
        "\n",
        "def modify_image(img):\n",
        "    # Random rotation\n",
        "    img = img.rotate(random.randint(-30, 30))\n",
        "\n",
        "    # Adjust brightness\n",
        "    enhancer = ImageEnhance.Brightness(img)\n",
        "    img = enhancer.enhance(random.uniform(0.5, 1.5))\n",
        "\n",
        "    # Add blur\n",
        "    img = img.filter(ImageFilter.GaussianBlur(radius=random.randint(0, 3)))\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def modify_all_images_in_directory(source_directory, destination_directory):\n",
        "    if not os.path.exists(destination_directory):\n",
        "        os.makedirs(destination_directory)\n",
        "\n",
        "    for filename in os.listdir(source_directory):\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            img_path = os.path.join(source_directory, filename)\n",
        "            img = Image.open(img_path)\n",
        "            modified_img = modify_image(img)\n",
        "            modified_img.save(os.path.join(destination_directory, filename))\n",
        "\n",
        "\n",
        "\n",
        "source_dir = 'dataset/validation/kanyelookalike'\n",
        "destination_dir = 'dataset/validation_modified/kanyelookalike'\n",
        "\n",
        "source_dir2 = 'dataset/validation/arianalookalike'\n",
        "destination_dir2 = 'dataset/validation_modified/arianalookalike'\n",
        "\n",
        "modify_all_images_in_directory(source_dir, destination_dir)\n",
        "modify_all_images_in_directory(source_dir2, destination_dir2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "def print_directory_contents(path):\n",
        "    for dirpath, dirnames, filenames in os.walk(path):\n",
        "        print(f\"Directory: {dirpath}\")\n",
        "        for filename in filenames:\n",
        "            print(f\"  File: {filename}\")\n",
        "\n",
        "# Example usage\n",
        "print_directory_contents('dataset/train')\n",
        "\n",
        "#load the model\n",
        "\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freezing the layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Adding custom layers\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "#compile and customise\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#prepare dataset\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'dataset/train',  # Path to the main directory\n",
        "    target_size=(224, 224),\n",
        "    batch_size=10,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    'dataset/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=10,\n",
        "    class_mode='binary')\n",
        "\n",
        "\n",
        "#train the model\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=1,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.n//validation_generator.batch_size\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "#evaluate the model\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    'dataset/validation',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=10,\n",
        "    class_mode='binary')\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print('Test accuracy:', test_accuracy)\n",
        "\n",
        "\n",
        "\n",
        "#evaluate the model\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    'dataset/validation_modified',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=10,\n",
        "    class_mode='binary')\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print('Test accuracy with blurs and brightness adjusted:', test_accuracy)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWLmRubFKPHE",
        "outputId": "11380905-b785-4483-f276-c304700b519d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory: dataset/train\n",
            "Directory: dataset/train/ariana\n",
            "  File: 6.jpg\n",
            "  File: 7.jpg\n",
            "  File: 5.jpg\n",
            "  File: 3.jpg\n",
            "  File: 2.jpg\n",
            "  File: 4.jpg\n",
            "  File: 10.jpg\n",
            "  File: 1.jpg\n",
            "  File: 9.jpg\n",
            "  File: 8.jpg\n",
            "Directory: dataset/train/kanye\n",
            "  File: 6.jpg\n",
            "  File: 7.jpg\n",
            "  File: 5.jpg\n",
            "  File: 3.jpg\n",
            "  File: 2.jpg\n",
            "  File: 4.jpg\n",
            "  File: 10.jpg\n",
            "  File: 1.jpg\n",
            "  File: 9.jpg\n",
            "  File: 8.jpg\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Found 20 images belonging to 2 classes.\n",
            "Found 20 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 28s 28s/step - loss: 0.9855 - accuracy: 0.4000 - val_loss: 0.9828 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 26s 26s/step - loss: 0.8336 - accuracy: 0.6000 - val_loss: 0.5101 - val_accuracy: 0.6500\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 26s 26s/step - loss: 0.4972 - accuracy: 0.7000 - val_loss: 0.2262 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 26s 26s/step - loss: 0.2648 - accuracy: 1.0000 - val_loss: 0.4277 - val_accuracy: 0.8000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 26s 26s/step - loss: 0.3051 - accuracy: 0.9000 - val_loss: 0.5442 - val_accuracy: 0.6000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 26s 26s/step - loss: 0.5206 - accuracy: 0.6000 - val_loss: 0.2794 - val_accuracy: 0.8500\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 26s 26s/step - loss: 0.4816 - accuracy: 0.6000 - val_loss: 0.0812 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 27s 27s/step - loss: 0.1235 - accuracy: 1.0000 - val_loss: 0.0861 - val_accuracy: 0.9500\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 18s 18s/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.1479 - val_accuracy: 0.9500\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 28s 28s/step - loss: 0.1738 - accuracy: 0.9000 - val_loss: 0.1681 - val_accuracy: 0.9500\n",
            "Found 20 images belonging to 2 classes.\n",
            "2/2 [==============================] - 13s 5s/step - loss: 0.9662 - accuracy: 0.6500\n",
            "Test accuracy: 0.6499999761581421\n",
            "Found 20 images belonging to 2 classes.\n",
            "2/2 [==============================] - 10s 5s/step - loss: 1.3018 - accuracy: 0.5000\n",
            "Test accuracy with blurs and brightness adjusted: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "9xfD64iEKO0U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}